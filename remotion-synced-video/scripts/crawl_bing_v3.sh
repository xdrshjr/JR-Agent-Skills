#!/bin/bash
# Bing Images çˆ¬å–è„šæœ¬ v3 - ç®€åŒ–ç‰ˆ

QUERY="${1:-futuristic robot}"
OUTPUT_DIR="${2:-./bing_images}"
LIMIT="${3:-3}"

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ðŸ–¼ï¸  Bing Images çˆ¬å–å·¥å…· v3"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "æœç´¢è¯: $QUERY"
echo ""

mkdir -p "$OUTPUT_DIR"

# æ­¥éª¤ 1: æ‰“å¼€ Bing Images (è‹±æ–‡ç•Œé¢æ›´ç¨³å®š)
echo "ðŸ“Œ Step 1: æ‰“å¼€ Bing Images..."
ENCODED_QUERY=$(python3 -c "import urllib.parse; print(urllib.parse.quote('''$QUERY'''))" 2>/dev/null || echo "$QUERY")
SEARCH_URL="https://www.bing.com/images/search?q=${ENCODED_QUERY}"

agent-browser open "$SEARCH_URL"
sleep 5
echo "   âœ“ é¡µé¢å·²åŠ è½½"

# æ­¥éª¤ 2: æˆªå›¾æŸ¥çœ‹
echo "ðŸ“Œ Step 2: æˆªå›¾..."
agent-browser screenshot "$OUTPUT_DIR/step1_bing.png"

# æ­¥éª¤ 3: ä½¿ç”¨ JS æå–æ‰€æœ‰å›¾ç‰‡
echo "ðŸ“Œ Step 3: æå–å›¾ç‰‡..."

JS_RESULT=$(agent-browser eval '
  Array.from(document.querySelectorAll("img"))
    .filter(img => img.src && img.src.includes("bing.net"))
    .slice(0, 10)
    .map(img => img.src)
' 2>&1)

echo "   JS è¿”å›ž: ${JS_RESULT:0:200}"

# æ­¥éª¤ 4: å…³é—­æµè§ˆå™¨
echo "ðŸ“Œ Step 4: å…³é—­æµè§ˆå™¨..."
agent-browser close

# æ­¥éª¤ 5: è§£æž URL
echo "ðŸ“Œ Step 5: è§£æž URL..."
echo "$JS_RESULT" | grep -oE 'https://[^"[:space:]]+bing\.net[^"[:space:]]+' | head -10 > /tmp/img_urls.txt || true

if [ ! -s /tmp/img_urls.txt ]; then
  echo "âš ï¸ å°è¯•å¤‡ç”¨æå–æ–¹æ³•..."
  echo "$JS_RESULT" | grep -oE 'https://[^"\[\],]+' | head -10 > /tmp/img_urls.txt || true
fi

# æ­¥éª¤ 6: ä¸‹è½½
echo "ðŸ“Œ Step 6: ä¸‹è½½å›¾ç‰‡..."

if [ -s /tmp/img_urls.txt ]; then
  echo "   æ‰¾åˆ° $(wc -l < /tmp/img_urls.txt) ä¸ª URL"
  
  COUNT=0
  while IFS= read -r URL && [ $COUNT -lt $LIMIT ]; do
    [ -z "$URL" ] && continue
    [[ "$URL" =~ ^https ]] || continue
    
    COUNT=$((COUNT + 1))
    OUTPUT_FILE="$OUTPUT_DIR/img_${COUNT}.jpg"
    
    echo ""
    echo "   [$COUNT/$LIMIT] ${URL:0:50}..."
    
    curl -sL "$URL" \
      -H "User-Agent: Mozilla/5.0" \
      -H "Referer: https://www.bing.com/" \
      --max-time 20 \
      -o "$OUTPUT_FILE" 2>/dev/null && echo "     âœ“ å®Œæˆ" || echo "     âœ— å¤±è´¥"
    
    # æ£€æŸ¥æ–‡ä»¶
    if [ -f "$OUTPUT_FILE" ]; then
      SIZE=$(stat -f%z "$OUTPUT_FILE" 2>/dev/null || stat -c%s "$OUTPUT_FILE" 2>/dev/null || echo "0")
      if [ "$SIZE" -lt 1024 ]; then
        rm -f "$OUTPUT_FILE"
        COUNT=$((COUNT - 1))
      fi
    fi
  done < /tmp/img_urls.txt
  
  echo ""
  echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "âœ… å®Œæˆ! æˆåŠŸä¸‹è½½ $COUNT å¼ å›¾ç‰‡"
  echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
else
  echo "âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡ URL"
fi

# æ˜¾ç¤ºç»“æžœ
echo ""
echo "ðŸ“ æ–‡ä»¶åˆ—è¡¨:"
ls -lh "$OUTPUT_DIR/" 2>/dev/null || echo "  æ— æ–‡ä»¶"

rm -f /tmp/img_urls.txt
