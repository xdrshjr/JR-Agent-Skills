#!/bin/bash
# Bing Images é«˜æ¸…çˆ¬å–è„šæœ¬ v4 - ä» m å±æ€§æå–

QUERY="${1:-futuristic AI robot}"
OUTPUT_DIR="${2:-./bing_images_hd}"
LIMIT="${3:-3}"

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ–¼ï¸  Bing Images é«˜æ¸…çˆ¬å–å·¥å…· v4"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "æœç´¢è¯: $QUERY"
echo ""

mkdir -p "$OUTPUT_DIR"

# æ­¥éª¤ 1: æ‰“å¼€ Bing
echo "ğŸ“Œ Step 1: æ‰“å¼€ Bing Images..."
ENCODED_QUERY=$(python3 -c "import urllib.parse; print(urllib.parse.quote('''$QUERY'''))" 2>/dev/null || echo "$QUERY")
agent-browser open "https://www.bing.com/images/search?q=${ENCODED_QUERY}"
sleep 5
echo "   âœ“ é¡µé¢å·²åŠ è½½"

# æ­¥éª¤ 2: æˆªå›¾
echo "ğŸ“Œ Step 2: æˆªå›¾..."
agent-browser screenshot "$OUTPUT_DIR/step1_search.png"

# æ­¥éª¤ 3: ä» m å±æ€§æå–å›¾ç‰‡æ•°æ®
echo "ğŸ“Œ Step 3: æå–å›¾ç‰‡æ•°æ®..."

JS_CODE='
(function() {
  var results = [];
  var seen = new Set();
  
  // Bing å°†å›¾ç‰‡æ•°æ®å­˜å‚¨åœ¨ m å±æ€§ä¸­
  document.querySelectorAll("a[m]").forEach(function(a) {
    try {
      var m = a.getAttribute("m");
      if (m) {
        var data = JSON.parse(m);
        if (data.murl && !seen.has(data.murl)) {
          seen.add(data.murl);
          results.push({
            url: data.murl,
            width: data.ow || 0,
            height: data.oh || 0,
            title: data.t || ""
          });
        }
      }
    } catch (e) {}
  });
  
  return results.slice(0, 20);
})()
'

RESULT=$(agent-browser eval "$JS_CODE" 2>&1)
echo "   æå–ç»“æœ: ${RESULT:0:300}"

# è§£æURL
echo "$RESULT" | grep -oE 'https://[^"\{\}\[\],]+' | head -20 > /tmp/img_urls.txt

# æ­¥éª¤ 4: å…³é—­æµè§ˆå™¨
echo "ğŸ“Œ Step 4: å…³é—­æµè§ˆå™¨..."
agent-browser close

# æ­¥éª¤ 5: ä¸‹è½½
echo "ğŸ“Œ Step 5: ä¸‹è½½é«˜æ¸…å›¾..."

if [ -s /tmp/img_urls.txt ]; then
  echo "   æ‰¾åˆ° $(wc -l < /tmp/img_urls.txt) ä¸ªURL"
  
  COUNT=0
  while IFS= read -r URL && [ $COUNT -lt $LIMIT ]; do
    [ -z "$URL" ] && continue
    
    COUNT=$((COUNT + 1))
    OUTPUT_FILE="$OUTPUT_DIR/img_${COUNT}_hd.jpg"
    
    echo ""
    echo "   [$COUNT/$LIMIT] ${URL:0:50}..."
    
    if curl -sL "$URL" \
         -H "User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36" \
         -H "Accept: image/webp,image/apng,image/*,*/*;q=0.8" \
         --max-time 30 \
         -o "$OUTPUT_FILE" 2>/dev/null; then
      
      FILE_SIZE=$(stat -f%z "$OUTPUT_FILE" 2>/dev/null || stat -c%s "$OUTPUT_FILE" 2>/dev/null || echo "0")
      
      if [ "$FILE_SIZE" -gt 102400 ]; then
        echo "      âœ… é«˜æ¸…å›¾ ($((FILE_SIZE/1024)) KB)"
      elif [ "$FILE_SIZE" -gt 51200 ]; then
        echo "      âœ“ è¾ƒå¤§å›¾ç‰‡ ($((FILE_SIZE/1024)) KB)"
      elif [ "$FILE_SIZE" -gt 10240 ]; then
        echo "      âš ï¸ ä¸­ç­‰è´¨é‡ ($((FILE_SIZE/1024)) KB)"
      else
        echo "      âŒ æ–‡ä»¶å¤ªå°"
        rm -f "$OUTPUT_FILE"
        COUNT=$((COUNT - 1))
      fi
    else
      echo "      âŒ ä¸‹è½½å¤±è´¥"
    fi
  done < /tmp/img_urls.txt
  
  echo ""
  echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo "âœ… å®Œæˆ! æˆåŠŸä¸‹è½½ $COUNT/$LIMIT å¼ é«˜æ¸…å›¾"
  echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
else
  echo "âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡URL"
fi

rm -f /tmp/img_urls.txt
ls -lh "$OUTPUT_DIR/"
